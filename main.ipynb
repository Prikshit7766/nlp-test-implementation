{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prikshit7766/nlp-test-implementation/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WB8BJ3eBdxq",
        "outputId": "126b6347-870c-4068-b268-e0a28220dd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlp test implementation\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/nlp test implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5PN9pS6WBP33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd4c34a-8bc9-4961-97a8-155ac9acc59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.2/473.2 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install -q pyspark==3.3.0 spark-nlp==4.3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4mimnpm0kPs",
        "outputId": "f3a216dc-d8fa-4691-a3a1-9193d6a5d5c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlptest\n",
            "  Downloading nlptest-1.2.0-py3-none-any.whl (54.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.2.2)\n",
            "Collecting transformers<=4.28.1 (from nlptest)\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from nlptest) (2.0.0+cu118)\n",
            "Collecting sentencepiece (from nlptest)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.10.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.5.6)\n",
            "Collecting jsonlines (from nlptest)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting langchain (from nlptest)\n",
            "  Downloading langchain-0.0.167-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.4/809.4 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai (from nlptest)\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate (from nlptest)\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from nlptest) (6.0.4)\n",
            "Collecting rouge-score (from nlptest)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers<=4.28.1->nlptest)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<=4.28.1->nlptest)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (4.65.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate->nlptest)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate->nlptest)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from evaluate->nlptest)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate->nlptest)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate->nlptest) (2023.4.0)\n",
            "Collecting responses<0.19 (from evaluate->nlptest)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->nlptest) (4.5.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->nlptest) (23.1.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain->nlptest)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain->nlptest)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain->nlptest)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain->nlptest)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (8.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nlptest) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nlptest) (2022.7.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score->nlptest) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score->nlptest) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score->nlptest) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nlptest) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nlptest) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nlptest) (3.1.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->nlptest) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->nlptest) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->nlptest) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->nlptest) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->nlptest) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->nlptest) (16.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->nlptest)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain->nlptest)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->nlptest)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate->nlptest) (9.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.1->nlptest) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.1->nlptest) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.1->nlptest) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->nlptest) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->nlptest) (2.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score->nlptest) (8.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->nlptest) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->nlptest)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=77ba06261f3fc1a813a338359e2ff864977e2fce086107c6b97ae6f86fdf126f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: tokenizers, sentencepiece, xxhash, mypy-extensions, multidict, marshmallow, jsonlines, frozenlist, dill, async-timeout, yarl, typing-inspect, rouge-score, responses, openapi-schema-pydantic, multiprocess, marshmallow-enum, huggingface-hub, aiosignal, transformers, dataclasses-json, aiohttp, openai, langchain, datasets, evaluate, nlptest\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 datasets-2.12.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.14.1 jsonlines-3.1.0 langchain-0.0.167 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 multiprocess-0.70.14 mypy-extensions-1.0.0 nlptest-1.2.0 openai-0.27.6 openapi-schema-pydantic-1.2.4 responses-0.18.0 rouge-score-0.1.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.28.1 typing-inspect-0.8.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install nlptest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gxA8sO530pPo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the dataframe from a CSV file\n",
        "df = pd.read_csv('FinalBalancedDataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV-M8nArMTGT",
        "outputId": "956a8805-a585-4ece-e086-301d077363b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56745, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgCcltPaMWmw",
        "outputId": "a139f476-2701-4c79-8fe0-914486b706dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "Toxicity      0\n",
              "tweet         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he1rcFKHMfVs",
        "outputId": "a5611ffd-5a7d-4754-f2da-8296224287b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56745 entries, 0 to 56744\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  56745 non-null  int64 \n",
            " 1   Toxicity    56745 non-null  int64 \n",
            " 2   tweet       56745 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W5jEQnZ4LxK-",
        "outputId": "a7b2b59f-a7e4-453a-bfbe-2e02aab5f1e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Toxicity                                              tweet\n",
              "0           0         0   @user when a father is dysfunctional and is s...\n",
              "1           1         0  @user @user thanks for #lyft credit i can't us...\n",
              "2           2         0                                bihday your majesty\n",
              "3           3         0  #model   i love u take with u all the time in ...\n",
              "4           4         0             factsguide: society now    #motivation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1429483d-9fba-4ac3-a15c-007db2bd0043\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Toxicity</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1429483d-9fba-4ac3-a15c-007db2bd0043')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1429483d-9fba-4ac3-a15c-007db2bd0043 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1429483d-9fba-4ac3-a15c-007db2bd0043');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2LxRP_Ivj20O"
      },
      "outputs": [],
      "source": [
        "df = df.rename(columns={'Toxicity': 'label'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KgRsdc2okxuK"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of each class in the target column\n",
        "class_counts = df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4B-yU6BKks9p"
      },
      "outputs": [],
      "source": [
        "# Determine the minimum count among the classes\n",
        "min_count = class_counts.min()\n",
        "\n",
        "# Limit the minimum count to 2,500 or the available count, whichever is smaller\n",
        "min_count = min(min_count, 2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TeKhhgtlL62o"
      },
      "outputs": [],
      "source": [
        "# Trim the data to have an equal number of records for each class\n",
        "trimmed_data = pd.concat([df[df['label'] == cls].sample(min_count) for cls in class_counts.index])\n",
        "\n",
        "# Randomly sample 5,000 records from the trimmed data\n",
        "trimmed_data = trimmed_data.sample(n=5000, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R2KFIUjslF1P"
      },
      "outputs": [],
      "source": [
        "trimmed_data=trimmed_data.drop(\"Unnamed: 0\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y6mtjDPNMHQH"
      },
      "outputs": [],
      "source": [
        "# Save the trimmed data as a CSV file\n",
        "trimmed_data.to_csv('trimmed_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mr_9Vf3NIh8"
      },
      "source": [
        "spark nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "OaHsm1ZbNLDr",
        "outputId": "e586ecf2-6f30-4449-b86c-cfc77d7ac4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  4.3.2\n",
            "Apache Spark version:  3.3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f3b15c65900>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7de2210e7675:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import sparknlp\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import pandas as pd\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "igeyKLFZNbRW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('trimmed_data.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X9zf0QpN35G",
        "outputId": "0276667a-9172-40a4-dcd6-0a624e623eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        }
      ],
      "source": [
        "spark_df = spark.createDataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ0J9uhCN4OC",
        "outputId": "daa73e4a-4511-429e-c443-e69c3eb28a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|               tweet|\n",
            "+-----+--------------------+\n",
            "|    0|wow september 1 2...|\n",
            "|    1|RT @UrbanCrazines...|\n",
            "|    1|RT @RuNeshaShamia...|\n",
            "|    0|i am thankful for...|\n",
            "|    0|justice has been ...|\n",
            "|    0|#diasoleado ðð...|\n",
            "|    0|#twinkletwinkle t...|\n",
            "|    0|5 more days until...|\n",
            "|    0|@user oh dear, is...|\n",
            "|    0|#visiting   goril...|\n",
            "|    0|this makes me #ma...|\n",
            "|    0|just been to view...|\n",
            "|    0| @user just read ...|\n",
            "|    0|#lucky   #dad to ...|\n",
            "|    1|council staff hav...|\n",
            "|    1|@SlothNG i can gu...|\n",
            "|    0|i am fantastic. #...|\n",
            "|    1|@chandraingram95 ...|\n",
            "|    0|These peanut butt...|\n",
            "|    0|@user the dance m...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbWxfJ0XSD_C",
        "outputId": "ea2369a3-bb25-414f-d5df-7e486c6a12c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=0, tweet='wow september 1 2015 me '),\n",
              " Row(label=1, tweet='RT @UrbanCraziness: \"nah go talk to ur hoes since u dont wanna text back n shit\" http://t.co/cvBzmjQXyO')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "spark_df.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FvSGDPoTVLQ",
        "outputId": "88f4c40d-9eed-4579-951f-e7ed83444019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0| 2500|\n",
            "|    1| 2500|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark_df.groupBy(\"label\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()\n",
        "\n",
        "    #Label indicating whether a tweet is toxic(1) or not(0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Qrp9i_T5vm"
      },
      "source": [
        "## Building  Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kaHzkxNT--l"
      },
      "source": [
        "### LogReg with CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5k5eoFU8TnVb"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci8gn2KkUK1P",
        "outputId": "3e53496b-3382-47d0-8659-605372a5029a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 190 ms, sys: 42.3 ms, total: 232 ms\n",
            "Wall time: 12.4 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"tweet\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "      \n",
        "normalizer = Normalizer() \\\n",
        "      .setInputCols([\"token\"]) \\\n",
        "      .setOutputCol(\"normalized\") # remove special characters\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "stemmer = Stemmer() \\\n",
        "      .setInputCols([\"cleanTokens\"]) \\\n",
        "      .setOutputCol(\"stem\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "      .setInputCols([\"stem\"]) \\\n",
        "      .setOutputCols([\"token_features\"]) \\\n",
        "      .setOutputAsArray(True) \\\n",
        "      .setCleanAnnotations(False) #The Finisher annotator helps you to clean the metadata (if it’s set to true) and output the results into an array\n",
        "\n",
        "countVectors = CountVectorizer(inputCol=\"token_features\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
        "\n",
        "\n",
        "nlp_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            countVectors,\n",
        "            ])\n",
        "\n",
        "nlp_model = nlp_pipeline.fit(spark_df)\n",
        "\n",
        "processed = nlp_model.transform(spark_df)\n",
        "\n",
        "processed.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxIOk_Yhdl97",
        "outputId": "8c2988ab-c010-46f2-b7dc-08f47fae2715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "|                                             tweet|                                    token_features|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "|the sellers accepted my offer. and the process ...|           [seller, accept, offer, process, begin]|\n",
            "|the microwave at work is broken, so my ghetto a...|[microwav, work, broken, ghetto, ass, put, hamb...|\n",
            "|RT @Oz_lito: @1stBlocJeremiah ctfu u bloody but...|[rt, ozlito, stblocjeremiah, ctfu, u, bloodi, y...|\n",
            "|it's so amazing how it's hard for disadvantaged...|[amaz, hard, disadvantag, footbal, settl, team,...|\n",
            "|          happy day!  #altwaystoheal  #healthy    |                 [happi, dai, altwaystoh, healthi]|\n",
            "|people who can get time off work to go to the e...|[peopl, get, time, work, go, euro, havent, gone...|\n",
            "|@user the library of alexandria wasn't the only...|[user, librari, alexandria, wasnt, on, oldest, ...|\n",
            "|somewhere in my thoughts.   #afternoon #me #nic...|[somewher, thought, afternoon, nice, cute, smil...|\n",
            "|back home k.lbvr  #rosabohneur #summer #paris  ...|[back, home, klbvr, rosabohneur, summer, pari, ...|\n",
            "|hating the conservative homophobes using this t...|[hate, conserv, homophob, us, tragedi, wai, spo...|\n",
            "|Going up to the view point and seeing star chil...|       [go, view, point, see, star, child, monkei]|\n",
            "|@user lolol i'm no better but i'm just saying.....|[user, lolol, im, better, im, saye, everi, sund...|\n",
            "|           @CallNeeshCakey pop wop and drop it tho|             [callneeshcakei, pop, wop, drop, tho]|\n",
            "|#petal   polar bear climb racing: angry polar b...|[petal, polar, bear, climb, race, angri, polar,...|\n",
            "|Love getting nudes from my bitches &#128520;&#1...|                          [love, get, nude, bitch]|\n",
            "|                You a hoe if you like gettin drunk|                        [hoe, like, gettin, drunk]|\n",
            "|best #lawofattraction #resources for #healing! ...|[best, lawofattract, resourc, heal, altwaystoh,...|\n",
            "|RT @thesexiertwin: Making today my bitch &#128520;|           [rt, thesexiertwin, make, todai, bitch]|\n",
            "|happy bihday last friday night (t.g.i.f.) ðð...|[happi, bihdai, last, fridai, night, tgif, ðððð...|\n",
            "|time to get happy! it's saturday ð    #satur...|[time, get, happi, saturdai, ð, saturdai, weekend]|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "processed.select('tweet','token_features').show(truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5LtVTjEhNCY",
        "outputId": "26c2720f-aafc-41c3-c042-b76a1f6036cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(token_features=['seller', 'accept', 'offer', 'process', 'begin']),\n",
              " Row(token_features=['microwav', 'work', 'broken', 'ghetto', 'ass', 'put', 'hamburg', 'patti', 'toaster', 'warm'])]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "processed.select('token_features').take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxf60EmQhbJT",
        "outputId": "9250b318-3a5a-4b26-f94f-e6785493c35d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(features=SparseVector(1315, {444: 1.0, 710: 1.0, 1077: 1.0})),\n",
              " Row(features=SparseVector(1315, {17: 1.0, 50: 1.0, 121: 1.0, 258: 1.0, 1099: 1.0}))]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "processed.select('features').take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_xjsdvMhkP2",
        "outputId": "933efe46-dbf7-4634-945e-09ebab461128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+\n",
            "|               tweet|            features|label|\n",
            "+--------------------+--------------------+-----+\n",
            "|the sellers accep...|(1315,[444,710,10...|    0|\n",
            "|the microwave at ...|(1315,[17,50,121,...|    1|\n",
            "|RT @Oz_lito: @1st...|(1315,[1,2,7,147,...|    1|\n",
            "|it's so amazing h...|(1315,[60,192,194...|    0|\n",
            "|  happy day!  #al...|(1315,[11,16,120,...|    0|\n",
            "|people who can ge...|(1315,[8,18,25,27...|    0|\n",
            "|@user the library...|(1315,[0,23,432,7...|    0|\n",
            "|somewhere in my t...|(1315,[77,108,153...|    0|\n",
            "|back home k.lbvr ...|(1315,[6,49,94,10...|    0|\n",
            "|hating the conser...|(1315,[34,61,62,8...|    0|\n",
            "|Going up to the v...|(1315,[18,39,352,...|    0|\n",
            "|@user lolol i'm n...|(1315,[0,5,87,139...|    0|\n",
            "|@CallNeeshCakey p...|(1315,[238,327,35...|    0|\n",
            "|#petal   polar be...|(1315,[66,196,234...|    0|\n",
            "|Love getting nude...|(1315,[1,6,8,429]...|    1|\n",
            "|You a hoe if you ...|(1315,[3,4,784,79...|    1|\n",
            "|best #lawofattrac...|(1315,[75,120,268...|    0|\n",
            "|RT @thesexiertwin...|(1315,[1,2,21,38]...|    1|\n",
            "|happy bihday last...|(1315,[16,19,85,8...|    0|\n",
            "|time to get happy...|(1315,[8,15,16,25...|    0|\n",
            "+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "processed.select('tweet','features','label').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu-GLmsziFGk",
        "outputId": "d5fbe845-58f4-4cfa-eaf4-75a4c99c94f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 3478\n",
            "Test Dataset Count: 1522\n"
          ]
        }
      ],
      "source": [
        "# set seed for reproducibility\n",
        "(trainingData, testData) = processed.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvFr-JX4iXZr",
        "outputId": "4d58e484-cf18-4f15-f863-f89724e07cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: long (nullable = true)\n",
            " |-- tweet: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- normalized: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- cleanTokens: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- stem: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainingData.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k9a8vfmigA7",
        "outputId": "4e8ffe4c-1a8a-4900-b663-c5906eb84942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+-----+------------------------------+----------+\n",
            "|                         tweet|label|                   probability|prediction|\n",
            "+------------------------------+-----+------------------------------+----------+\n",
            "|this is very good camp food...|    0|[0.9669286261089691,0.03307...|       0.0|\n",
            "|have a great weekend, frien...|    0|[0.9663494727116793,0.03365...|       0.0|\n",
            "|view for lunch ð #spain ...|    0|[0.9639490023980476,0.03605...|       0.0|\n",
            "| @user make sure you regist...|    0|[0.9607156733538808,0.03928...|       0.0|\n",
            "|travel to me   #inshot #gir...|    0|[0.9547928449600995,0.04520...|       0.0|\n",
            "|serious holiday blues!first...|    0|[0.9538267459821224,0.04617...|       0.0|\n",
            "|whats happening here... pls...|    0|[0.9536519186543062,0.04634...|       0.0|\n",
            "|a small yet super treat aft...|    0|[0.952650344938334,0.047349...|       0.0|\n",
            "|#ana   bull hill climb: you...|    0|[0.9519699899803007,0.04803...|       0.0|\n",
            "| @user omg i won't be able ...|    0|[0.9499760047084319,0.05002...|       0.0|\n",
            "+------------------------------+-----+------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "lrModel = lr.fit(trainingData)\n",
        "\n",
        "predictions = lrModel.transform(testData)\n",
        "\n",
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"tweet\",'label',\"probability\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwN8xaHbiqia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20beeffe-3ca6-44ec-a621-8fb6eaf67a46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8883048620236531"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "\n",
        "evaluator.evaluate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "y_true = predictions.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()"
      ],
      "metadata": {
        "id": "FYajcXvLqUCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.prediction.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ar14RoZqWHS",
        "outputId": "a0296e0e-3da3-43fc-e6d5-e2d600627deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    772\n",
              "1.0    750\n",
              "Name: prediction, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix = confusion_matrix(list(y_true.label.astype(int)), list(y_pred.prediction.astype(int)))\n",
        "cnf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY4tJ5s-qXHh",
        "outputId": "29fdd72c-3ad1-4434-ea06-00c2c76fa381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[676,  74],\n",
              "       [ 96, 676]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nth8dSgBqYQO",
        "outputId": "11a31d7d-1ff8-40c5-fa81-bb0fd072bcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89       750\n",
            "           1       0.90      0.88      0.89       772\n",
            "\n",
            "    accuracy                           0.89      1522\n",
            "   macro avg       0.89      0.89      0.89      1522\n",
            "weighted avg       0.89      0.89      0.89      1522\n",
            "\n",
            "0.8883048620236531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LogReg with TFIDF"
      ],
      "metadata": {
        "id": "zyvAqx4IqeV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "\n",
        "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "\n",
        "nlp_pipeline_tf = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf,\n",
        "            ])\n",
        "\n",
        "nlp_model_tf = nlp_pipeline_tf.fit(spark_df)\n",
        "\n",
        "processed_tf = nlp_model_tf.transform(spark_df)\n",
        "\n",
        "processed_tf.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZe2I5giqafU",
        "outputId": "3f82977e-bef2-4639-da4f-5e1db2ceb170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed for reproducibility\n",
        "processed_tf.select('tweet','features','label').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJQQgWEMqnki",
        "outputId": "3f5f30ce-e91a-4343-98fa-03bc67317b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+\n",
            "|               tweet|            features|label|\n",
            "+--------------------+--------------------+-----+\n",
            "|the sellers accep...|(10000,[1513,2657...|    0|\n",
            "|the microwave at ...|(10000,[770,3776,...|    1|\n",
            "|RT @Oz_lito: @1st...|(10000,[701,865,2...|    1|\n",
            "|it's so amazing h...|(10000,[468,874,1...|    0|\n",
            "|  happy day!  #al...|(10000,[353,5285,...|    0|\n",
            "|people who can ge...|(10000,[696,1149,...|    0|\n",
            "|@user the library...|(10000,[1233,1991...|    0|\n",
            "|somewhere in my t...|(10000,[55,349,52...|    0|\n",
            "|back home k.lbvr ...|(10000,[969,1568,...|    0|\n",
            "|hating the conser...|(10000,[15,2069,2...|    0|\n",
            "|Going up to the v...|(10000,[2028,4416...|    0|\n",
            "|@user lolol i'm n...|(10000,[1678,2182...|    0|\n",
            "|@CallNeeshCakey p...|(10000,[2952,6409...|    0|\n",
            "|#petal   polar be...|(10000,[253,454,4...|    0|\n",
            "|Love getting nude...|(10000,[701,5900,...|    1|\n",
            "|You a hoe if you ...|(10000,[2712,3330...|    1|\n",
            "|best #lawofattrac...|(10000,[353,763,2...|    0|\n",
            "|RT @thesexiertwin...|(10000,[532,701,3...|    1|\n",
            "|happy bihday last...|(10000,[987,2576,...|    0|\n",
            "|time to get happy...|(10000,[2309,3043...|    0|\n",
            "+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = processed_tf.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33kcbAF9qq1v",
        "outputId": "dcfdf05b-bd30-4319-da31-85d7cd93093d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 3478\n",
            "Test Dataset Count: 1522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lrModel_tf = lr.fit(trainingData)\n",
        "\n",
        "predictions_tf = lrModel_tf.transform(testData)\n",
        "\n",
        "predictions_tf.select(\"tweet\",\"label\",\"probability\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ats8xaDZquAz",
        "outputId": "fb7bc341-e150-418d-e622-d26030806a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+-----+------------------------------+----------+\n",
            "|                         tweet|label|                   probability|prediction|\n",
            "+------------------------------+-----+------------------------------+----------+\n",
            "|this is very good camp food...|    0|[0.9687570456086259,0.03124...|       0.0|\n",
            "|a small yet super treat aft...|    0|[0.957801237378701,0.042198...|       0.0|\n",
            "|pause ð #goodmorning #ha...|    0|[0.9557869861490598,0.04421...|       0.0|\n",
            "|check  steve kerr rips offi...|    0|[0.9509212051985791,0.04907...|       0.0|\n",
            "|whats happening here... pls...|    0|[0.9475181156488829,0.05248...|       0.0|\n",
            "| @user make sure you regist...|    0|[0.9474741661899445,0.05252...|       0.0|\n",
            "|amazing 1st week with a new...|    0|[0.9472651405161227,0.05273...|       0.0|\n",
            "|take yourself away sometime...|    0|[0.9472601685410799,0.05273...|       0.0|\n",
            "|serious holiday blues!first...|    0|[0.946126846216106,0.053873...|       0.0|\n",
            "|In-N-Out is like the sunshi...|    0|[0.9455719383609537,0.05442...|       0.0|\n",
            "+------------------------------+-----+------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = predictions_tf.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions_tf.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQrkoHXIqzOG",
        "outputId": "d7357811-7a95-4f12-9ec6-b2142abc67b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       750\n",
            "           1       0.88      0.86      0.87       772\n",
            "\n",
            "    accuracy                           0.87      1522\n",
            "   macro avg       0.87      0.87      0.87      1522\n",
            "weighted avg       0.87      0.87      0.87      1522\n",
            "\n",
            "0.8679369250985546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest with TFIDF"
      ],
      "metadata": {
        "id": "qjjIHVpvq2JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
        "                            featuresCol=\"features\", \\\n",
        "                            numTrees = 100, \\\n",
        "                            maxDepth = 4, \\\n",
        "                            maxBins = 32)\n",
        "\n",
        "# Train model with Training Data\n",
        "rfModel = rf.fit(trainingData)\n",
        "predictions_rf = rfModel.transform(testData)"
      ],
      "metadata": {
        "id": "-_KIKZpXq01z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_rf.select(\"tweet\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDaD7B-Pq6Vw",
        "outputId": "6c0006cc-74f1-4df4-e520-d9d4fae0227c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+-----+----------+\n",
            "|                         tweet|                   probability|label|prediction|\n",
            "+------------------------------+------------------------------+-----+----------+\n",
            "|thank you lord for this bea...|[0.5828660171374689,0.41713...|    0|       0.0|\n",
            "| @user @user   thursday #lo...|[0.577210260625392,0.422789...|    0|       0.0|\n",
            "|  mornin folks have a #posi...|[0.5769128262281499,0.42308...|    0|       0.0|\n",
            "| @user tomorrow i meet up w...|[0.5762152691262067,0.42378...|    0|       0.0|\n",
            "|love around me, i love my g...|[0.5761596875209244,0.42384...|    0|       0.0|\n",
            "| @user when they nap on you...|[0.5741740834178458,0.42582...|    0|       0.0|\n",
            "|  lovely gift on a sunny da...|[0.5739713235545756,0.42602...|    0|       0.0|\n",
            "| â #wti drops to lows nea...|[0.5727125788658238,0.42728...|    0|       0.0|\n",
            "| â #new zealand current a...|[0.5703414959230629,0.42965...|    0|       0.0|\n",
            "|@user &lt;3 &lt;3 listen to...|[0.5679519053743953,0.43204...|    0|       0.0|\n",
            "+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = predictions_rf.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions_rf.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPBlQyRwq-HF",
        "outputId": "57755528-115c-4d7b-acc8-2ecee3f6e793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       750\n",
            "           1       0.92      0.77      0.84       772\n",
            "\n",
            "    accuracy                           0.85      1522\n",
            "   macro avg       0.86      0.85      0.85      1522\n",
            "weighted avg       0.86      0.85      0.85      1522\n",
            "\n",
            "0.8488830486202366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LogReg with Spark NLP Glove Word Embeddings"
      ],
      "metadata": {
        "id": "ZfwMzVVjrEyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"tweet\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "      .setInputCols([\"token\"]) \\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        "      .setInputCols([\"document\",'cleanTokens'])\\\n",
        "      .setOutputCol(\"embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "    \n",
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "      .setInputCols([\"sentence_embeddings\"]) \\\n",
        "      .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
        "      .setOutputAsVector(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "explodeVectors = SQLTransformer(statement=\n",
        "      \"SELECT EXPLODE(finished_sentence_embeddings) AS features, * FROM __THIS__\")\n",
        "\n",
        "\n",
        "\n",
        "nlp_pipeline_w2v = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            embeddings_finisher,\n",
        "            explodeVectors,\n",
        "            ])\n",
        "\n",
        "nlp_model_w2v = nlp_pipeline_w2v.fit(spark_df)\n",
        "\n",
        "processed_w2v = nlp_model_w2v.transform(spark_df)\n",
        "\n",
        "processed_w2v.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy8B95BwrAyj",
        "outputId": "b385fac4-ee04-40cb-b1a7-ca6f8a227281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_w2v.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHaDIqKkrOye",
        "outputId": "3c2d6054-9951-4aa2-8869-8cf84179512f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['features',\n",
              " 'label',\n",
              " 'tweet',\n",
              " 'document',\n",
              " 'token',\n",
              " 'normalized',\n",
              " 'cleanTokens',\n",
              " 'embeddings',\n",
              " 'sentence_embeddings',\n",
              " 'finished_sentence_embeddings']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_w2v.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V65-exZarTDw",
        "outputId": "71b19abf-fea1-4d86-938b-622f2ca01c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------------+\n",
            "|            features|label|               tweet|            document|               token|          normalized|         cleanTokens|          embeddings| sentence_embeddings|finished_sentence_embeddings|\n",
            "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------------+\n",
            "|[0.02773400582373...|    0|the sellers accep...|[{document, 0, 54...|[{token, 0, 2, th...|[{token, 0, 2, th...|[{token, 4, 10, s...|[{word_embeddings...|[{sentence_embedd...|        [[0.0277340058237...|\n",
            "|[-0.2108502835035...|    1|the microwave at ...|[{document, 0, 10...|[{token, 0, 2, th...|[{token, 0, 2, th...|[{token, 4, 12, m...|[{word_embeddings...|[{sentence_embedd...|        [[-0.210850283503...|\n",
            "|[0.01915432699024...|    1|RT @Oz_lito: @1st...|[{document, 0, 98...|[{token, 0, 1, RT...|[{token, 0, 1, RT...|[{token, 0, 1, RT...|[{word_embeddings...|[{sentence_embedd...|        [[0.0191543269902...|\n",
            "|[0.18952007591724...|    0|it's so amazing h...|[{document, 0, 13...|[{token, 0, 3, it...|[{token, 0, 2, it...|[{token, 8, 14, a...|[{word_embeddings...|[{sentence_embedd...|        [[0.1895200759172...|\n",
            "|[-0.1074697524309...|    0|  happy day!  #al...|[{document, 0, 41...|[{token, 2, 6, ha...|[{token, 2, 6, ha...|[{token, 2, 6, ha...|[{word_embeddings...|[{sentence_embedd...|        [[-0.107469752430...|\n",
            "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_w2v.select('finished_sentence_embeddings').take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No3LSBQJrTjn",
        "outputId": "492cdbf0-dc4a-44c7-c59e-6834b7b4dc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(finished_sentence_embeddings=[DenseVector([0.0277, 0.3477, 0.0511, 0.2483, 0.2075, -0.1634, -0.0111, 0.3807, 0.1292, -0.3561, -0.0374, 0.1651, 0.2746, -0.0301, -0.0101, -0.2521, 0.0388, 0.1938, -0.0494, 0.4389, -0.2251, -0.2997, 0.0481, -0.0251, 0.0692, 0.0416, -0.0182, -0.3399, 0.0555, -0.2028, -0.0598, 0.5491, -0.3812, -0.3454, 0.0936, 0.2491, 0.0228, -0.2965, -0.2358, -0.3809, -0.3403, -0.1401, 0.1044, -0.3468, -0.1381, -0.2201, -0.2853, -0.3443, 0.1875, -0.4726, 0.4313, -0.1614, 0.1751, 0.7783, -0.1908, -1.5875, -0.2479, -0.3684, 1.4258, -0.0262, -0.0699, 0.2124, 0.0581, -0.156, 0.5504, -0.156, 0.2305, 0.4646, -0.0853, -0.446, -0.0811, -0.2875, -0.372, -0.195, -0.1316, 0.0803, -0.4341, -0.0463, -0.8069, -0.4025, 0.3565, 0.0571, -0.3571, -0.1755, -1.0731, 0.0975, 0.1237, -0.1974, -0.1266, -0.2944, -0.1871, 0.0597, -0.1935, -0.102, -0.2789, 0.2095, 0.0365, -0.002, 0.5753, 0.6163])])]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IF SQLTransformer IS NOT USED INSIDE THE PIPELINE, WE CAN EXPLODE OUTSIDE\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "# processed_w2v= processed_w2v.withColumn(\"features\", explode(processed_w2v.finished_sentence_embeddings))"
      ],
      "metadata": {
        "id": "7ktzrWZRrg24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_w2v.select(\"features\").take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TIXtWhRrqvg",
        "outputId": "4220f8be-a7db-43d6-8680-7544b763ddcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(features=DenseVector([0.0277, 0.3477, 0.0511, 0.2483, 0.2075, -0.1634, -0.0111, 0.3807, 0.1292, -0.3561, -0.0374, 0.1651, 0.2746, -0.0301, -0.0101, -0.2521, 0.0388, 0.1938, -0.0494, 0.4389, -0.2251, -0.2997, 0.0481, -0.0251, 0.0692, 0.0416, -0.0182, -0.3399, 0.0555, -0.2028, -0.0598, 0.5491, -0.3812, -0.3454, 0.0936, 0.2491, 0.0228, -0.2965, -0.2358, -0.3809, -0.3403, -0.1401, 0.1044, -0.3468, -0.1381, -0.2201, -0.2853, -0.3443, 0.1875, -0.4726, 0.4313, -0.1614, 0.1751, 0.7783, -0.1908, -1.5875, -0.2479, -0.3684, 1.4258, -0.0262, -0.0699, 0.2124, 0.0581, -0.156, 0.5504, -0.156, 0.2305, 0.4646, -0.0853, -0.446, -0.0811, -0.2875, -0.372, -0.195, -0.1316, 0.0803, -0.4341, -0.0463, -0.8069, -0.4025, 0.3565, 0.0571, -0.3571, -0.1755, -1.0731, 0.0975, 0.1237, -0.1974, -0.1266, -0.2944, -0.1871, 0.0597, -0.1935, -0.102, -0.2789, 0.2095, 0.0365, -0.002, 0.5753, 0.6163]))]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_w2v.select('tweet','features','label').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6sUJ0B1rsI3",
        "outputId": "c7bde627-f748-41af-97bf-72b6a14a7c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+\n",
            "|               tweet|            features|label|\n",
            "+--------------------+--------------------+-----+\n",
            "|the sellers accep...|[0.02773400582373...|    0|\n",
            "|the microwave at ...|[-0.2108502835035...|    1|\n",
            "|RT @Oz_lito: @1st...|[0.01915432699024...|    1|\n",
            "|it's so amazing h...|[0.18952007591724...|    0|\n",
            "|  happy day!  #al...|[-0.1074697524309...|    0|\n",
            "|people who can ge...|[0.02151191607117...|    0|\n",
            "|@user the library...|[0.04796125739812...|    0|\n",
            "|somewhere in my t...|[0.09011052548885...|    0|\n",
            "|back home k.lbvr ...|[0.08463780581951...|    0|\n",
            "|hating the conser...|[0.01190709043294...|    0|\n",
            "|Going up to the v...|[0.33191305398941...|    0|\n",
            "|@user lolol i'm n...|[-0.0720526576042...|    0|\n",
            "|@CallNeeshCakey p...|[-0.1222900003194...|    0|\n",
            "|#petal   polar be...|[-0.1342255622148...|    0|\n",
            "|Love getting nude...|[0.46387749910354...|    1|\n",
            "|You a hoe if you ...|[-0.0718640014529...|    1|\n",
            "|best #lawofattrac...|[0.02930671349167...|    0|\n",
            "|RT @thesexiertwin...|[-0.0468870028853...|    1|\n",
            "|happy bihday last...|[-0.0360176376998...|    0|\n",
            "|time to get happy...|[-0.1852795779705...|    0|\n",
            "+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed for reproducibility\n",
        "(trainingData, testData) = processed_w2v.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e71PGu44rvHI",
        "outputId": "153f51d2-28fc-42f3-d13d-f0da83ce732d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 3478\n",
            "Test Dataset Count: 1522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## By removing such rows, we can optimize the performance of our machine learning algorithms, as we can skip the computation for those rows where the features vector is all zeros.\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(\"long\")\n",
        "def num_nonzeros(v):\n",
        "    return v.numNonzeros()\n",
        "\n",
        "testData = testData.where(num_nonzeros(\"features\") != 0)"
      ],
      "metadata": {
        "id": "LGOyiPpXr9dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrModel_w2v = lr.fit(trainingData)"
      ],
      "metadata": {
        "id": "Ay0AzdSEsHEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_w2v = lrModel_w2v.transform(testData)\n",
        "\n",
        "predictions_w2v.select(\"tweet\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWydyWz4sPZx",
        "outputId": "6b59b27f-8ac6-4f7d-959b-3b88c5f1782a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------+-----------------------------------------+-----+----------+\n",
            "|                                                       tweet|                              probability|label|prediction|\n",
            "+------------------------------------------------------------+-----------------------------------------+-----+----------+\n",
            "|                                 morning everyone!   #monday|[0.9700461803788555,0.029953819621144517]|    0|       0.0|\n",
            "|                 @user @user @user @user   saturday  friends| [0.9688514337163213,0.03114856628367868]|    0|       0.0|\n",
            "|   i am thankful for vacation days. #thankful #positive     |  [0.967206006437128,0.03279399356287205]|    0|       0.0|\n",
            "| @user 3 weeks until holiday!!!!!!! #pougal #villa #famil...| [0.9642743078981164,0.03572569210188359]|    0|       0.0|\n",
            "|          flights booked to see my girl @user this summer!  | [0.9627148800456357,0.03728511995436434]|    0|       0.0|\n",
            "|  #friday peepsðð @user @user @user @user @user @user |[0.9593425016815605,0.040657498318439456]|    0|       0.0|\n",
            "|   i am thankful for having a home. #thankful #positive     |[0.9592610133784619,0.040738986621538076]|    0|       0.0|\n",
            "|@user @user i've had these experiences in europe as an am...| [0.9544739540058239,0.04552604599417609]|    1|       0.0|\n",
            "|tickets for all 3 @user autumn internationals purchased!!...| [0.9532933913049713,0.04670660869502874]|    0|       0.0|\n",
            "|the 4 secret ingredients for a truly   life  #happiness #...|   [0.9525638845219,0.047436115478100005]|    0|       0.0|\n",
            "+------------------------------------------------------------+-----------------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "y_true = predictions_w2v.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions_w2v.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRSp0XWesWTK",
        "outputId": "781f4b8e-a6b6-4b85-8cb0-e498ae823b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       766\n",
            "           1       0.88      0.85      0.87       753\n",
            "\n",
            "    accuracy                           0.87      1519\n",
            "   macro avg       0.87      0.87      0.87      1519\n",
            "weighted avg       0.87      0.87      0.87      1519\n",
            "\n",
            "0.8722843976300197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_w2v.select('tweet','cleanTokens.result').show(truncate=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALT8svaOsdPp",
        "outputId": "397cf821-c84a-48f0-f673-8e7370a51653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "|                                             tweet|                                            result|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "|the sellers accepted my offer. and the process ...|       [sellers, accepted, offer, process, begins]|\n",
            "|the microwave at work is broken, so my ghetto a...|[microwave, work, broken, ghetto, ass, put, ham...|\n",
            "|RT @Oz_lito: @1stBlocJeremiah ctfu u bloody but...|[RT, Ozlito, stBlocJeremiah, ctfu, u, bloody, y...|\n",
            "|it's so amazing how it's hard for disadvantaged...|[amazing, hard, disadvantaged, footballers, set...|\n",
            "|          happy day!  #altwaystoheal  #healthy    |              [happy, day, altwaystoheal, healthy]|\n",
            "|people who can get time off work to go to the e...|[people, get, time, work, go, euros, havent, go...|\n",
            "|@user the library of alexandria wasn't the only...|[user, library, alexandria, wasnt, one, oldest,...|\n",
            "|somewhere in my thoughts.   #afternoon #me #nic...|[somewhere, thoughts, afternoon, nice, cute, sm...|\n",
            "|back home k.lbvr  #rosabohneur #summer #paris  ...|[back, home, klbvr, rosabohneur, summer, paris,...|\n",
            "|hating the conservative homophobes using this t...|[hating, conservative, homophobes, using, trage...|\n",
            "|Going up to the view point and seeing star chil...| [Going, view, point, seeing, star, child, monkey]|\n",
            "|@user lolol i'm no better but i'm just saying.....|[user, lolol, im, better, im, saying, every, su...|\n",
            "|           @CallNeeshCakey pop wop and drop it tho|             [CallNeeshCakey, pop, wop, drop, tho]|\n",
            "|#petal   polar bear climb racing: angry polar b...|[petal, polar, bear, climb, racing, angry, pola...|\n",
            "|Love getting nudes from my bitches &#128520;&#1...|                   [Love, getting, nudes, bitches]|\n",
            "|                You a hoe if you like gettin drunk|                        [hoe, like, gettin, drunk]|\n",
            "|best #lawofattraction #resources for #healing! ...|[best, lawofattraction, resources, healing, alt...|\n",
            "|RT @thesexiertwin: Making today my bitch &#128520;|         [RT, thesexiertwin, Making, today, bitch]|\n",
            "|happy bihday last friday night (t.g.i.f.) ðð...|[happy, bihday, last, friday, night, tgif, ðððð...|\n",
            "|time to get happy! it's saturday ð    #satur...|[time, get, happy, saturday, ð, saturday, weekend]|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier DL + Glove + Basic text processing"
      ],
      "metadata": {
        "id": "llFmTEOZ0xPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQqsc4O47Wwd",
        "outputId": "02f9ae37-ac44-449d-baa7-1a2f0bfe21d7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|               tweet|\n",
            "+-----+--------------------+\n",
            "|    0|wow september 1 2...|\n",
            "|    1|RT @UrbanCrazines...|\n",
            "|    1|RT @RuNeshaShamia...|\n",
            "|    0|i am thankful for...|\n",
            "|    0|justice has been ...|\n",
            "|    0|#diasoleado ðð...|\n",
            "|    0|#twinkletwinkle t...|\n",
            "|    0|5 more days until...|\n",
            "|    0|@user oh dear, is...|\n",
            "|    0|#visiting   goril...|\n",
            "|    0|this makes me #ma...|\n",
            "|    0|just been to view...|\n",
            "|    0| @user just read ...|\n",
            "|    0|#lucky   #dad to ...|\n",
            "|    1|council staff hav...|\n",
            "|    1|@SlothNG i can gu...|\n",
            "|    0|i am fantastic. #...|\n",
            "|    1|@chandraingram95 ...|\n",
            "|    0|These peanut butt...|\n",
            "|    0|@user the dance m...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark_df.toPandas()\n",
        "df = df.rename({'tweet':'text'}, axis = 1)"
      ],
      "metadata": {
        "id": "p8W40gBH7o-m"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Save train and test data as CSV files\n",
        "train_df.to_csv('train_data.csv', index=False)\n",
        "test_df.to_csv('test_data.csv', index=False)"
      ],
      "metadata": {
        "id": "RAYuSKpn7egr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"text\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "      .setInputCols([\"token\"]) \\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "      .setInputCols([\"cleanTokens\"]) \\\n",
        "      .setOutputCol(\"lemma\")\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        "      .setInputCols([\"document\",'lemma'])\\\n",
        "      .setOutputCol(\"embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCol(\"class\")\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setMaxEpochs(5)\\\n",
        "      .setEnableOutputLogs(True)\n",
        "\n",
        "clf_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemma, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            classsifierdl])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmRsXla90zGV",
        "outputId": "f15ba54b-2a03-42e0-d333-8a58f6258268"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData= spark_df = spark.createDataFrame(train_df)"
      ],
      "metadata": {
        "id": "31Jt91Ia8UY2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb82DFRNDESN",
        "outputId": "43259890-e6e0-4d45-de7a-ce400022ed75"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|                text|\n",
            "+-----+--------------------+\n",
            "|    1|RT @PRIVALEDGE: U...|\n",
            "|    0|@BasketballPics w...|\n",
            "|    0|the simple things...|\n",
            "|    0|#model   i love u...|\n",
            "|    0|' #urdu poetry #b...|\n",
            "|    0|  father's day. i...|\n",
            "|    0|okay i need a sac...|\n",
            "|    1|Niccas be gassing...|\n",
            "|    1|RT @gotmollylove:...|\n",
            "|    1|RT @KMURDER1000: ...|\n",
            "|    1|@HeelsOverSneaks ...|\n",
            "|    0|this looks like m...|\n",
            "|    0|full week now and...|\n",
            "|    0|disney gator atta...|\n",
            "|    1|@Groovy_Ear strai...|\n",
            "|    0|#raw food diet be...|\n",
            "|    0|Mark Teixeira fin...|\n",
            "|    0|@user @user @user...|\n",
            "|    0|okay @user i am l...|\n",
            "|    0|my beautiful best...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pipelineModel = clf_pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "8vSVofBY0-SP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf classifier_dl_pipeline_glove"
      ],
      "metadata": {
        "id": "0sz1_1Wy1bRl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pipeline.save('classifier_dl_pipeline_glove')"
      ],
      "metadata": {
        "id": "-4pASRhz3Uz7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pipelineModel = clf_pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "xhhGvKQc3X6-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testData= spark_df = spark.createDataFrame(test_df)"
      ],
      "metadata": {
        "id": "y4vY8wUafzxk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = clf_pipelineModel.transform(testData).select('label','text',\"class.result\").toPandas()\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "62AmSKcI3bgx",
        "outputId": "b7d73a7c-e9c2-4b16-c220-27f4e81bd8bd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text result\n",
              "0      0  i hate when people take shit that don't belong...    [1]\n",
              "1      0                              no cock out though.      [1]\n",
              "2      0    &amp; #grateful that #money comes to me in #...    [0]\n",
              "3      1             #democrats are the 1st to tell   jokes    [1]\n",
              "4      1  And it's always the black bitches that's const...    [1]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdc18813-28c7-4209-8866-0b2626805641\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>i hate when people take shit that don't belong...</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>no cock out though.</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;amp; #grateful that #money comes to me in #...</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#democrats are the 1st to tell   jokes</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>And it's always the black bitches that's const...</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdc18813-28c7-4209-8866-0b2626805641')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdc18813-28c7-4209-8866-0b2626805641 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdc18813-28c7-4209-8866-0b2626805641');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "df['result'] = df['result'].apply(lambda x: x[0])\n",
        "\n",
        "print(classification_report(df[\"label\"].astype(str), df[\"result\"]))\n",
        "\n",
        "print(accuracy_score(df.label.astype(str), df.result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DQrXJr53gzv",
        "outputId": "c49446db-53d0-4f55-ffb9-a12466f7e46d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.88       730\n",
            "           1       0.90      0.85      0.88       770\n",
            "\n",
            "    accuracy                           0.88      1500\n",
            "   macro avg       0.88      0.88      0.88      1500\n",
            "weighted avg       0.88      0.88      0.88      1500\n",
            "\n",
            "0.8753333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP TEST"
      ],
      "metadata": {
        "id": "HCBpVFyM5p72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlptest\n",
        "!pip install johnsnowlabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XiDdOgbj3r4k",
        "outputId": "e8343fed-568d-4441-f05f-e1afad796c8f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nlptest in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.2.2)\n",
            "Requirement already satisfied: transformers<=4.28.1 in /usr/local/lib/python3.10/dist-packages (from nlptest) (4.28.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from nlptest) (2.0.0+cu118)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from nlptest) (0.1.99)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.10.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from nlptest) (1.5.6)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from nlptest) (3.1.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from nlptest) (0.0.167)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from nlptest) (0.27.6)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from nlptest) (0.4.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from nlptest) (6.0.4)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (from nlptest) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (0.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.1->nlptest) (4.65.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate->nlptest) (2.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate->nlptest) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate->nlptest) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate->nlptest) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate->nlptest) (2023.4.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->nlptest) (0.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->nlptest) (4.5.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->nlptest) (23.1.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (1.2.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->nlptest) (8.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nlptest) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nlptest) (2022.7.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score->nlptest) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score->nlptest) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score->nlptest) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nlptest) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nlptest) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nlptest) (3.1.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->nlptest) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->nlptest) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->nlptest) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->nlptest) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->nlptest) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->nlptest) (16.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->nlptest) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->nlptest) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->nlptest) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->nlptest) (0.8.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate->nlptest) (9.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.1->nlptest) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.1->nlptest) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.1->nlptest) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->nlptest) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->nlptest) (2.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score->nlptest) (8.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->nlptest) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->nlptest) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting johnsnowlabs\n",
            "  Downloading johnsnowlabs-4.4.5-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyspark==3.1.2 (from johnsnowlabs)\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spark-nlp==4.4.1 (from johnsnowlabs)\n",
            "  Downloading spark_nlp-4.4.1-py2.py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.7/486.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlu==4.2.0 (from johnsnowlabs)\n",
            "  Downloading nlu-4.2.0-py3-none-any.whl (639 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m639.9/639.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spark-nlp-display==4.1 (from johnsnowlabs)\n",
            "  Downloading spark_nlp_display-4.1-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.4/95.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (1.22.4)\n",
            "Collecting dataclasses (from johnsnowlabs)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (2.27.1)\n",
            "Collecting databricks-api (from johnsnowlabs)\n",
            "  Downloading databricks_api-0.8.0-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (1.10.7)\n",
            "Collecting colorama (from johnsnowlabs)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from nlu==4.2.0->johnsnowlabs) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from nlu==4.2.0->johnsnowlabs) (1.5.3)\n",
            "Collecting py4j==0.10.9 (from pyspark==3.1.2->johnsnowlabs)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from spark-nlp-display==4.1->johnsnowlabs) (7.34.0)\n",
            "Collecting svgwrite==1.4 (from spark-nlp-display==4.1->johnsnowlabs)\n",
            "  Downloading svgwrite-1.4-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting databricks-cli (from databricks-api->johnsnowlabs)\n",
            "  Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->johnsnowlabs) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->nlu==4.2.0->johnsnowlabs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->nlu==4.2.0->johnsnowlabs) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (8.1.3)\n",
            "Collecting pyjwt>=1.7.0 (from databricks-cli->databricks-api->johnsnowlabs)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->spark-nlp-display==4.1->johnsnowlabs)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->spark-nlp-display==4.1->johnsnowlabs) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->spark-nlp-display==4.1->johnsnowlabs) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->spark-nlp-display==4.1->johnsnowlabs) (0.2.6)\n",
            "Building wheels for collected packages: pyspark, databricks-cli\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880756 sha256=68d68e45513d1281c17fe299fdb0122b805e3c3cca9c8005c512f1d1603e8cf9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/70/50/7882e1bcb5693225f7cc86698f10953201b48b3f36317c2d18\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143860 sha256=6ce2e605852a9b5478ba3216b08ca6fde4e1fc8c38f6b6fa9d166aaf27682819\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/63/93/5402c1a09c1868a59d0b05013484e07af97a9d7b3dbd5bd39a\n",
            "Successfully built pyspark databricks-cli\n",
            "Installing collected packages: spark-nlp, py4j, dataclasses, svgwrite, pyspark, pyjwt, jedi, colorama, databricks-cli, spark-nlp-display, nlu, databricks-api, johnsnowlabs\n",
            "  Attempting uninstall: spark-nlp\n",
            "    Found existing installation: spark-nlp 4.3.2\n",
            "    Uninstalling spark-nlp-4.3.2:\n",
            "      Successfully uninstalled spark-nlp-4.3.2\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.5\n",
            "    Uninstalling py4j-0.10.9.5:\n",
            "      Successfully uninstalled py4j-0.10.9.5\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.3.0\n",
            "    Uninstalling pyspark-3.3.0:\n",
            "      Successfully uninstalled pyspark-3.3.0\n",
            "Successfully installed colorama-0.4.6 databricks-api-0.8.0 databricks-cli-0.17.7 dataclasses-0.6 jedi-0.18.2 johnsnowlabs-4.4.5 nlu-4.2.0 py4j-0.10.9 pyjwt-2.7.0 pyspark-3.1.2 spark-nlp-4.4.1 spark-nlp-display-4.1 svgwrite-1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "com",
                  "dataclasses",
                  "py4j",
                  "pyspark",
                  "sparknlp"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "lBKWu3fYb_e_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData= pd.read_csv(\"train_data.csv\")"
      ],
      "metadata": {
        "id": "5dU4TIA_5t-V"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2E2VkRZF6xRz",
        "outputId": "dcaecb9f-d7ed-4ee0-a06b-be39f3d4a36d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "0         1                    RT @PRIVALEDGE: Undercover hoes\n",
              "1         0  @BasketballPics whoever made this twitter does...\n",
              "2         0  the simple things in life make one happy #smil...\n",
              "3         0  #model   i love u take with u all the time in ...\n",
              "4         0  ' #urdu poetry #beutiful poetry   poetry  #2 l...\n",
              "...     ...                                                ...\n",
              "3495      1  Live birds found in Elmo doll at US-Mexico bor...\n",
              "3496      1  \"but pussy is the root of all drama an attribu...\n",
              "3497      1                     @tGR0Z you's a nasty lil bitch\n",
              "3498      0  with le sister! #instatraveling #instamoment #...\n",
              "3499      1  this much #hatred, #xenophobia, #islamophobia,...\n",
              "\n",
              "[3500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24291333-3adb-41f1-8ccb-f3e2ba124e8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @PRIVALEDGE: Undercover hoes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@BasketballPics whoever made this twitter does...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>the simple things in life make one happy #smil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>' #urdu poetry #beutiful poetry   poetry  #2 l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3495</th>\n",
              "      <td>1</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3496</th>\n",
              "      <td>1</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3497</th>\n",
              "      <td>1</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3498</th>\n",
              "      <td>0</td>\n",
              "      <td>with le sister! #instatraveling #instamoment #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499</th>\n",
              "      <td>1</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24291333-3adb-41f1-8ccb-f3e2ba124e8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24291333-3adb-41f1-8ccb-f3e2ba124e8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24291333-3adb-41f1-8ccb-f3e2ba124e8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = 'train_data.csv'"
      ],
      "metadata": {
        "id": "CO4w7w1yE9l6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robustness Tests"
      ],
      "metadata": {
        "id": "0RBf4Uw9Jo--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nlptest import Harness\n",
        "harness = Harness(task=\"text-classification\", model=clf_pipelineModel, data=traindata)\n"
      ],
      "metadata": {
        "id": "rxlWI-_U6WDe"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "harness.configure(\n",
        "{'defaults': {'min_pass_rate': 0.65},\n",
        " 'tests': {'robustness': {\n",
        "                          'uppercase':{'min_pass_rate': 0.60},\n",
        "                          'add_typo':{'min_pass_rate': 0.90}},\n",
        "\n",
        "          }\n",
        " }\n",
        " )"
      ],
      "metadata": {
        "id": "6RqR2gS76lwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0219b92-2cdc-4dc3-b82f-3d07481f2b02"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'defaults': {'min_pass_rate': 0.65},\n",
              " 'tests': {'robustness': {'uppercase': {'min_pass_rate': 0.6},\n",
              "   'add_typo': {'min_pass_rate': 0.9}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harness.generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxipTyPNDnGG",
        "outputId": "65a95748-6597-4770-dfa9-1479bcdbbd83"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating testcases...: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harness.testcases()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FkOEMUr8FKIz",
        "outputId": "0a49cf5b-f97c-4f0c-a149-ecedc80b6f17"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category  test_type  \\\n",
              "0     robustness  uppercase   \n",
              "1     robustness  uppercase   \n",
              "2     robustness  uppercase   \n",
              "3     robustness  uppercase   \n",
              "4     robustness  uppercase   \n",
              "...          ...        ...   \n",
              "6995  robustness   add_typo   \n",
              "6996  robustness   add_typo   \n",
              "6997  robustness   add_typo   \n",
              "6998  robustness   add_typo   \n",
              "6999  robustness   add_typo   \n",
              "\n",
              "                                               original  \\\n",
              "0                       RT @PRIVALEDGE: Undercover hoes   \n",
              "1     @BasketballPics whoever made this twitter does...   \n",
              "2     the simple things in life make one happy #smil...   \n",
              "3     #model   i love u take with u all the time in ...   \n",
              "4     ' #urdu poetry #beutiful poetry   poetry  #2 l...   \n",
              "...                                                 ...   \n",
              "6995  Live birds found in Elmo doll at US-Mexico bor...   \n",
              "6996  \"but pussy is the root of all drama an attribu...   \n",
              "6997                     @tGR0Z you's a nasty lil bitch   \n",
              "6998  with le sister! #instatraveling #instamoment #...   \n",
              "6999  this much #hatred, #xenophobia, #islamophobia,...   \n",
              "\n",
              "                                              test_case expected_result  \n",
              "0                       RT @PRIVALEDGE: UNDERCOVER HOES               0  \n",
              "1     @BASKETBALLPICS WHOEVER MADE THIS TWITTER DOES...               1  \n",
              "2     THE SIMPLE THINGS IN LIFE MAKE ONE HAPPY #SMIL...               1  \n",
              "3     #MODEL   I LOVE U TAKE WITH U ALL THE TIME IN ...               1  \n",
              "4     ' #URDU POETRY #BEUTIFUL POETRY   POETRY  #2 L...               1  \n",
              "...                                                 ...             ...  \n",
              "6995  Live birds found in Elmo doll at US-Mexico bor...               1  \n",
              "6996  \"but pussy is the root of all drama an attribu...               0  \n",
              "6997                     @tGR0Z you's a nasty lil bitch               0  \n",
              "6998  with le sister! #instatraveling #ipstamoment #...               0  \n",
              "6999  this much #hatred, #xenophobia, #islamophobia,...               1  \n",
              "\n",
              "[7000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31fbeebe-2b54-4556-a454-2eee014eb86a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>test_type</th>\n",
              "      <th>original</th>\n",
              "      <th>test_case</th>\n",
              "      <th>expected_result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>RT @PRIVALEDGE: Undercover hoes</td>\n",
              "      <td>RT @PRIVALEDGE: UNDERCOVER HOES</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>@BasketballPics whoever made this twitter does...</td>\n",
              "      <td>@BASKETBALLPICS WHOEVER MADE THIS TWITTER DOES...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>the simple things in life make one happy #smil...</td>\n",
              "      <td>THE SIMPLE THINGS IN LIFE MAKE ONE HAPPY #SMIL...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#MODEL   I LOVE U TAKE WITH U ALL THE TIME IN ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>' #urdu poetry #beutiful poetry   poetry  #2 l...</td>\n",
              "      <td>' #URDU POETRY #BEUTIFUL POETRY   POETRY  #2 L...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6995</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6996</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6997</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6998</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>with le sister! #instatraveling #instamoment #...</td>\n",
              "      <td>with le sister! #instatraveling #ipstamoment #...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6999</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31fbeebe-2b54-4556-a454-2eee014eb86a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31fbeebe-2b54-4556-a454-2eee014eb86a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31fbeebe-2b54-4556-a454-2eee014eb86a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harness.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YSiIsSYFM0Q",
        "outputId": "96ea935d-9272-4a10-b9da-c8d374e90af9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running testcases... : 100%|██████████| 7000/7000 [49:09<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harness.generated_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gcpNAx-ZFY4I",
        "outputId": "7c0451df-16f6-4b29-8bb2-01e0ff4c1b97"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category  test_type  \\\n",
              "0     robustness  uppercase   \n",
              "1     robustness  uppercase   \n",
              "2     robustness  uppercase   \n",
              "3     robustness  uppercase   \n",
              "4     robustness  uppercase   \n",
              "...          ...        ...   \n",
              "6995  robustness   add_typo   \n",
              "6996  robustness   add_typo   \n",
              "6997  robustness   add_typo   \n",
              "6998  robustness   add_typo   \n",
              "6999  robustness   add_typo   \n",
              "\n",
              "                                               original  \\\n",
              "0                       RT @PRIVALEDGE: Undercover hoes   \n",
              "1     @BasketballPics whoever made this twitter does...   \n",
              "2     the simple things in life make one happy #smil...   \n",
              "3     #model   i love u take with u all the time in ...   \n",
              "4     ' #urdu poetry #beutiful poetry   poetry  #2 l...   \n",
              "...                                                 ...   \n",
              "6995  Live birds found in Elmo doll at US-Mexico bor...   \n",
              "6996  \"but pussy is the root of all drama an attribu...   \n",
              "6997                     @tGR0Z you's a nasty lil bitch   \n",
              "6998  with le sister! #instatraveling #instamoment #...   \n",
              "6999  this much #hatred, #xenophobia, #islamophobia,...   \n",
              "\n",
              "                                              test_case expected_result  \\\n",
              "0                       RT @PRIVALEDGE: UNDERCOVER HOES               0   \n",
              "1     @BASKETBALLPICS WHOEVER MADE THIS TWITTER DOES...               1   \n",
              "2     THE SIMPLE THINGS IN LIFE MAKE ONE HAPPY #SMIL...               1   \n",
              "3     #MODEL   I LOVE U TAKE WITH U ALL THE TIME IN ...               1   \n",
              "4     ' #URDU POETRY #BEUTIFUL POETRY   POETRY  #2 L...               1   \n",
              "...                                                 ...             ...   \n",
              "6995  Live birds found in Elmo doll at US-Mexico bor...               1   \n",
              "6996  \"but pussy is the root of all drama an attribu...               0   \n",
              "6997                     @tGR0Z you's a nasty lil bitch               0   \n",
              "6998  with le sister! #instatraveling #ipstamoment #...               0   \n",
              "6999  this much #hatred, #xenophobia, #islamophobia,...               1   \n",
              "\n",
              "     actual_result  pass  \n",
              "0                0  True  \n",
              "1                1  True  \n",
              "2                1  True  \n",
              "3                1  True  \n",
              "4                1  True  \n",
              "...            ...   ...  \n",
              "6995             1  True  \n",
              "6996             0  True  \n",
              "6997             0  True  \n",
              "6998             0  True  \n",
              "6999             1  True  \n",
              "\n",
              "[7000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9f86d1b-99ad-45f7-83d8-15e3e5bfda0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>test_type</th>\n",
              "      <th>original</th>\n",
              "      <th>test_case</th>\n",
              "      <th>expected_result</th>\n",
              "      <th>actual_result</th>\n",
              "      <th>pass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>RT @PRIVALEDGE: Undercover hoes</td>\n",
              "      <td>RT @PRIVALEDGE: UNDERCOVER HOES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>@BasketballPics whoever made this twitter does...</td>\n",
              "      <td>@BASKETBALLPICS WHOEVER MADE THIS TWITTER DOES...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>the simple things in life make one happy #smil...</td>\n",
              "      <td>THE SIMPLE THINGS IN LIFE MAKE ONE HAPPY #SMIL...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#MODEL   I LOVE U TAKE WITH U ALL THE TIME IN ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>robustness</td>\n",
              "      <td>uppercase</td>\n",
              "      <td>' #urdu poetry #beutiful poetry   poetry  #2 l...</td>\n",
              "      <td>' #URDU POETRY #BEUTIFUL POETRY   POETRY  #2 L...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6995</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6996</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6997</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6998</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>with le sister! #instatraveling #instamoment #...</td>\n",
              "      <td>with le sister! #instatraveling #ipstamoment #...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6999</th>\n",
              "      <td>robustness</td>\n",
              "      <td>add_typo</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9f86d1b-99ad-45f7-83d8-15e3e5bfda0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9f86d1b-99ad-45f7-83d8-15e3e5bfda0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9f86d1b-99ad-45f7-83d8-15e3e5bfda0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bias Tests"
      ],
      "metadata": {
        "id": "kbHRNKO4OuRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "harness = Harness(task=\"text-classification\", model=clf_pipelineModel, data=traindata)"
      ],
      "metadata": {
        "id": "B5GXQBV2Pmvi"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "harness.configure(\n",
        "{'defaults': {'min_pass_rate': 0.65},\n",
        " 'tests': {'bias': {'replace_to_black_lastnames': {'min_pass_rate': 0.66}, \n",
        "                          'replace_to_white_lastnames':{'min_pass_rate': 0.60}}\n",
        "          }\n",
        " }\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4vaWUz4O5Dk",
        "outputId": "a6db7cf6-7fa1-409a-c846-bea5768269d6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'defaults': {'min_pass_rate': 0.65},\n",
              " 'tests': {'bias': {'replace_to_black_lastnames': {'min_pass_rate': 0.66},\n",
              "   'replace_to_white_lastnames': {'min_pass_rate': 0.6}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harness.generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32cxeNgSP0se",
        "outputId": "6522641a-500b-43a5-e539-092cd8f50927"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating testcases...: 100%|██████████| 1/1 [00:00<00:00, 6462.72it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harness.testcases()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "52EjqqPeP2vM",
        "outputId": "ccc55f58-1d2d-4e6d-d5d4-43327b134655"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     category                   test_type  \\\n",
              "0        bias  replace_to_black_lastnames   \n",
              "1        bias  replace_to_black_lastnames   \n",
              "2        bias  replace_to_black_lastnames   \n",
              "3        bias  replace_to_black_lastnames   \n",
              "4        bias  replace_to_black_lastnames   \n",
              "...       ...                         ...   \n",
              "6995     bias  replace_to_white_lastnames   \n",
              "6996     bias  replace_to_white_lastnames   \n",
              "6997     bias  replace_to_white_lastnames   \n",
              "6998     bias  replace_to_white_lastnames   \n",
              "6999     bias  replace_to_white_lastnames   \n",
              "\n",
              "                                               original  \\\n",
              "0                       RT @PRIVALEDGE: Undercover hoes   \n",
              "1     @BasketballPics whoever made this twitter does...   \n",
              "2     the simple things in life make one happy #smil...   \n",
              "3     #model   i love u take with u all the time in ...   \n",
              "4     ' #urdu poetry #beutiful poetry   poetry  #2 l...   \n",
              "...                                                 ...   \n",
              "6995  Live birds found in Elmo doll at US-Mexico bor...   \n",
              "6996  \"but pussy is the root of all drama an attribu...   \n",
              "6997                     @tGR0Z you's a nasty lil bitch   \n",
              "6998  with le sister! #instatraveling #instamoment #...   \n",
              "6999  this much #hatred, #xenophobia, #islamophobia,...   \n",
              "\n",
              "                                              test_case expected_result  \n",
              "0                       RT @PRIVALEDGE: Undercover hoes               0  \n",
              "1     @BasketballPics whoever made this twitter does...               1  \n",
              "2     the simple things in life make one happy #smil...               1  \n",
              "3     #model   i love u take with u all the time in ...               1  \n",
              "4     ' #urdu poetry #beutiful poetry   poetry  #2 l...               1  \n",
              "...                                                 ...             ...  \n",
              "6995  Live birds found in Elmo doll at US-Mexico bor...               1  \n",
              "6996  \"but pussy is the root of all drama an attribu...               0  \n",
              "6997                     @tGR0Z you's a nasty lil bitch               0  \n",
              "6998  with Vandyke sister! #instatraveling #instamom...               0  \n",
              "6999  this much #hatred, #xenophobia, #islamophobia,...               1  \n",
              "\n",
              "[7000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85bd4224-a663-47e9-b4a8-915277666717\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>test_type</th>\n",
              "      <th>original</th>\n",
              "      <th>test_case</th>\n",
              "      <th>expected_result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>RT @PRIVALEDGE: Undercover hoes</td>\n",
              "      <td>RT @PRIVALEDGE: Undercover hoes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>@BasketballPics whoever made this twitter does...</td>\n",
              "      <td>@BasketballPics whoever made this twitter does...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>the simple things in life make one happy #smil...</td>\n",
              "      <td>the simple things in life make one happy #smil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>' #urdu poetry #beutiful poetry   poetry  #2 l...</td>\n",
              "      <td>' #urdu poetry #beutiful poetry   poetry  #2 l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6995</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6996</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6997</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6998</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>with le sister! #instatraveling #instamoment #...</td>\n",
              "      <td>with Vandyke sister! #instatraveling #instamom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6999</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85bd4224-a663-47e9-b4a8-915277666717')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85bd4224-a663-47e9-b4a8-915277666717 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85bd4224-a663-47e9-b4a8-915277666717');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harness.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqIppMQYP4-S",
        "outputId": "d92bf0e5-5a9d-4d07-b9f2-159fdba52fa0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running testcases... : 100%|██████████| 7000/7000 [48:27<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harness.generated_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xHlhxSbyP6_S",
        "outputId": "109ee533-9340-4bd0-f03d-850c4b144634"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     category                   test_type  \\\n",
              "0        bias  replace_to_black_lastnames   \n",
              "1        bias  replace_to_black_lastnames   \n",
              "2        bias  replace_to_black_lastnames   \n",
              "3        bias  replace_to_black_lastnames   \n",
              "4        bias  replace_to_black_lastnames   \n",
              "...       ...                         ...   \n",
              "6995     bias  replace_to_white_lastnames   \n",
              "6996     bias  replace_to_white_lastnames   \n",
              "6997     bias  replace_to_white_lastnames   \n",
              "6998     bias  replace_to_white_lastnames   \n",
              "6999     bias  replace_to_white_lastnames   \n",
              "\n",
              "                                               original  \\\n",
              "0                       RT @PRIVALEDGE: Undercover hoes   \n",
              "1     @BasketballPics whoever made this twitter does...   \n",
              "2     the simple things in life make one happy #smil...   \n",
              "3     #model   i love u take with u all the time in ...   \n",
              "4     ' #urdu poetry #beutiful poetry   poetry  #2 l...   \n",
              "...                                                 ...   \n",
              "6995  Live birds found in Elmo doll at US-Mexico bor...   \n",
              "6996  \"but pussy is the root of all drama an attribu...   \n",
              "6997                     @tGR0Z you's a nasty lil bitch   \n",
              "6998  with le sister! #instatraveling #instamoment #...   \n",
              "6999  this much #hatred, #xenophobia, #islamophobia,...   \n",
              "\n",
              "                                              test_case expected_result  \\\n",
              "0                       RT @PRIVALEDGE: Undercover hoes               0   \n",
              "1     @BasketballPics whoever made this twitter does...               1   \n",
              "2     the simple things in life make one happy #smil...               1   \n",
              "3     #model   i love u take with u all the time in ...               1   \n",
              "4     ' #urdu poetry #beutiful poetry   poetry  #2 l...               1   \n",
              "...                                                 ...             ...   \n",
              "6995  Live birds found in Elmo doll at US-Mexico bor...               1   \n",
              "6996  \"but pussy is the root of all drama an attribu...               0   \n",
              "6997                     @tGR0Z you's a nasty lil bitch               0   \n",
              "6998  with Vandyke sister! #instatraveling #instamom...               0   \n",
              "6999  this much #hatred, #xenophobia, #islamophobia,...               1   \n",
              "\n",
              "     actual_result  pass  \n",
              "0                0  True  \n",
              "1                1  True  \n",
              "2                1  True  \n",
              "3                1  True  \n",
              "4                1  True  \n",
              "...            ...   ...  \n",
              "6995             1  True  \n",
              "6996             0  True  \n",
              "6997             0  True  \n",
              "6998             0  True  \n",
              "6999             1  True  \n",
              "\n",
              "[7000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eba9aa59-9b12-481c-bad5-2c7baafa36ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>test_type</th>\n",
              "      <th>original</th>\n",
              "      <th>test_case</th>\n",
              "      <th>expected_result</th>\n",
              "      <th>actual_result</th>\n",
              "      <th>pass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>RT @PRIVALEDGE: Undercover hoes</td>\n",
              "      <td>RT @PRIVALEDGE: Undercover hoes</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>@BasketballPics whoever made this twitter does...</td>\n",
              "      <td>@BasketballPics whoever made this twitter does...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>the simple things in life make one happy #smil...</td>\n",
              "      <td>the simple things in life make one happy #smil...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_black_lastnames</td>\n",
              "      <td>' #urdu poetry #beutiful poetry   poetry  #2 l...</td>\n",
              "      <td>' #urdu poetry #beutiful poetry   poetry  #2 l...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6995</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "      <td>Live birds found in Elmo doll at US-Mexico bor...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6996</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "      <td>\"but pussy is the root of all drama an attribu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6997</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "      <td>@tGR0Z you's a nasty lil bitch</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6998</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>with le sister! #instatraveling #instamoment #...</td>\n",
              "      <td>with Vandyke sister! #instatraveling #instamom...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6999</th>\n",
              "      <td>bias</td>\n",
              "      <td>replace_to_white_lastnames</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "      <td>this much #hatred, #xenophobia, #islamophobia,...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eba9aa59-9b12-481c-bad5-2c7baafa36ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eba9aa59-9b12-481c-bad5-2c7baafa36ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eba9aa59-9b12-481c-bad5-2c7baafa36ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=harness.generated_results()"
      ],
      "metadata": {
        "id": "HZifIdCcDiwl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQfMAkj-DmHj",
        "outputId": "14c56e49-191a-4c39-a1e6-a4c491f75da7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data = df.groupby(['test_type', 'pass'])"
      ],
      "metadata": {
        "id": "j_bIjIRhP9px"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_counts = grouped_data.size()"
      ],
      "metadata": {
        "id": "IgAQfnPYRDJI"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_counts "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR44UZ9ND7PF",
        "outputId": "229c8d16-887b-477e-f5c7-8eb36d57eb70"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "test_type                   pass \n",
              "replace_to_black_lastnames  False     244\n",
              "                            True     3256\n",
              "replace_to_white_lastnames  False     163\n",
              "                            True     3337\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "14BRoAbMI8fivFE6Vfz8J0smDURkh1g26",
      "authorship_tag": "ABX9TyN3jh0a89bBtnZ6jMYFYRZL",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}